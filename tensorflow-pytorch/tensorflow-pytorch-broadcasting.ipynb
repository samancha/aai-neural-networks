{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt1:  \n",
    "Create a one-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.  \n",
    "Create a two-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.  \n",
    "Create a three-dimensional tensor in both TensorFlow and PyTorch that contains the values of your interest. Print the tensor to the console for each framework.  \n",
    "Create a function in both TensorFlow and PyTorch that takes two tensors as input and returns the sum of their elements. Test the function with 1D, 2D, and 3D tensors. This function will demonstrate how to perform element-wise addition between two tensors and then sum all elements of the resulting tensor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch tensor: 1D\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "tensorflow tensor: 1D\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "\n",
      "pytorch tensor: 2D\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensorflow tensor: 2D\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "pytorch tensor: 3D\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "tensorflow tensor: 3D\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# one dimensional tensor \n",
    "print(\"pytorch tensor: 1D\")\n",
    "torch_tensor1 = t.tensor([1, 2, 3, 4, 5])\n",
    "print(torch_tensor1)\n",
    "\n",
    "print(\"tensorflow tensor: 1D\")\n",
    "tf_tensor1 = tf.constant([1, 2, 3, 4, 5])\n",
    "print(tf_tensor1)\n",
    "\n",
    "# two dimensional tensor\n",
    "print(\"\\npytorch tensor: 2D\")\n",
    "torch_tensor2 = t.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(torch_tensor2)\n",
    "\n",
    "print(\"tensorflow tensor: 2D\")\n",
    "tf_tensor2 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(tf_tensor2)\n",
    "\n",
    "# three dimensional tensor\n",
    "print(\"\\npytorch tensor: 3D\")\n",
    "torch_tensor3 = t.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(torch_tensor3)\n",
    "\n",
    "print(\"tensorflow tensor: 3D\")\n",
    "tf_tensor3 = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(tf_tensor3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tensors(tensor1, tensor2):\n",
    "    if isinstance(tensor1, (t.Tensor)):\n",
    "        print(\"pytorch sum\")\n",
    "        sum = t.add(tensor1, tensor2)\n",
    "    elif isinstance(tensor1, (tf.Tensor)):\n",
    "        print(\"tensorflow sum\")\n",
    "        sum = tf.add(tensor1, tensor2)\n",
    "    else:\n",
    "        print(\"Tensor type not found simply adding tensors, found type: \", type(tensor1))\n",
    "        sum = tensor1 + tensor2\n",
    "    print(sum)\n",
    "    return sum\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch sum\n",
      "tensor([ 2,  4,  6,  8, 10])\n",
      "tensorflow sum\n",
      "tf.Tensor([ 2  4  6  8 10], shape=(5,), dtype=int32)\n",
      "\n",
      "\n",
      "pytorch sum\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n",
      "tensorflow sum\n",
      "tf.Tensor(\n",
      "[[ 2  4  6]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "\n",
      "pytorch sum\n",
      "tensor([[[ 2,  4],\n",
      "         [ 6,  8]],\n",
      "\n",
      "        [[10, 12],\n",
      "         [14, 16]]])\n",
      "tensorflow sum\n",
      "tf.Tensor(\n",
      "[[[ 2  4]\n",
      "  [ 6  8]]\n",
      "\n",
      " [[10 12]\n",
      "  [14 16]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sum_tensor = sum_tensors(torch_tensor1, torch_tensor1)\n",
    "sum_tensor = sum_tensors(tf_tensor1, tf_tensor1)\n",
    "print('\\n')\n",
    "sum_tensor = sum_tensors(torch_tensor2, torch_tensor2)\n",
    "sum_tensor = sum_tensors(tf_tensor2, tf_tensor2)\n",
    "print('\\n')\n",
    "sum_tensor = sum_tensors(torch_tensor3, torch_tensor3)\n",
    "sum_tensor = sum_tensors(tf_tensor3, tf_tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt2:\n",
    "Broadcasting is a powerful mechanism that allows TensorFlow and PyTorch to work with tensors of different shapes during arithmetic operations. Describe how broadcasting works in tensor operations, providing a simple example to illustrate your explanation.  \n",
    "Discuss why broadcasting is important and how it enhances the flexibility of tensor operations in building neural network models.  \n",
    "Explain what limitations or challenges might arise when relying on broadcasting, particularly in the context of ensuring model correctness and efficiency.  \n",
    "\n",
    "\n",
    "When dealing with tensor operations, if tensor shapes are not the same and ranks are different then we have to transform them into compatible shapes. By making them in the compatible shape broadcasting can be easily applied to perform the tasks. It does this by stretching the smaller tensor to match the shape of the larger tensor. This is done by replicating the smaller tensor along the missing dimensions.  \n",
    "This is particularly useful in neural network models, due to it's ability to automatically and efficiently handle operations between tensors of different shapes. This allows for more flexibility in the design of neural network models, as it simplifies the process of performing element-wise operations without the need for manually matching array shapes.  \n",
    "Some limitations that broadcasting introduces are that it can sometimes lead to unexpected results if the user is not careful. This can be due to the fact that broadcasting can automatically adjust tensor shapes, which may lead to unintended results if the user is not aware of how broadcasting works. Additionally, broadcasting can sometimes lead to inefficiencies in terms of memory usage, as it may require additional memory to store the broadcasted tensor. Therefore, it is important to be aware of the limitations of broadcasting and to use it judiciously to ensure model correctness and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 2  3  4]\n",
      "   [ 6  7  8]]\n",
      "\n",
      "  [[ 4  5  6]\n",
      "   [ 8  9 10]]]\n",
      "\n",
      "\n",
      " [[[ 6  7  8]\n",
      "   [10 11 12]]\n",
      "\n",
      "  [[ 8  9 10]\n",
      "   [12 13 14]]]], shape=(2, 2, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Adding new axis to T2 by .expand_dims() at its trailing end\n",
    "broadcasted_T3 = tf.expand_dims(tf_tensor3, axis=-1)\n",
    "\n",
    "# arithmetic operation\n",
    "sum = broadcasted_T3+ tf_tensor2\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
